{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresja liniowa i logistyczna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wstęp\n",
    "\n",
    "![A group of people on Titanic looking at an iceberg.](titanic.png \"Stable diffusion image: A photograph of Titanic crushing with an iceberg made from a matrix\")\n",
    "\n",
    "\n",
    "Celem laboratorium jest zapoznanie z najprostszymi narzędziami do predykcji na podstawie danych - regresją liniową i logistyczną. \n",
    "Zapoznasz się na nim z następującymi tematami:\n",
    "* przygotowaniem danych, w szczególności z:\n",
    "  * ładowaniem danych,\n",
    "  * typami danych,\n",
    "  * obsługą wartości brakujących,\n",
    "  * oceną przydatności atrybutów,\n",
    "  * skalowaniem wartości;\n",
    "* regresją liniową, w szczególności z:\n",
    "  * podziałem zbioru na część treningową i testową,\n",
    "  * oceną jakości modelu,\n",
    "  * walidacją skrośną,\n",
    "  * wyszukiwaniem hiperparametrów;\n",
    "* regresją logistyczną, w szczególności z:\n",
    "  * różnymi rodzajami błędów klasyfikacji,\n",
    "  * problemem przeuczenia, niedouczenia oraz metodami regularyzacji modelu.\n",
    "\n",
    "Na pierwszych zajęciach możesz korzystać ze środowiska Google Colab i zdalnego środowiska obliczeniowego. Jeżeli interesuje Cię skonfigurowanie Pythona u siebie, to niezbędne informacje są podane w sekcji \"Konfiguracja własnego komputera\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wykorzystywane biblioteki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na zajęciach korzystać będziesz z kilku popularnych bibliotek do Pythona, które umożliwiają klasyfikację danych, ich wizualizację czy preprocessing. Są to:\n",
    "1. [numpy](https://numpy.org/) - klasyczna bibliotek do wykonywania obliczeń macierzowych. Pozwala na efektywne przeprowadzanie obliczeń naukowych (np. na macierzach). Dobrze współgra z biblioteką pandas,\n",
    "1. [pandas](https://pandas.pydata.org/) - narzędzie do analizy danych, ich strukturyzowania oraz manipulacji na nich,\n",
    "1. [sklearn](https://scikit-learn.org/stable/) - narzędzie do przeprowadzania klasyfikacji, regresji, clusteringu itp. Biblioteka ta jest dość rozbudowana i pozwala także na mapowanie danych czy redukcję wymiarów. Więcej informacji znajdziesz w podanym linku,\n",
    "1. [missingno](https://pypi.org/project/missingno/) - narzędzie do wizualizacji kompletności danych (brakujących wartości),\n",
    "1. [seaborn](https://seaborn.pydata.org/) - kompleksowe narzędzie do wizualizacji danych jako takich. Pozwala na stworzenie bardzo szerokiej gamy wykresów w zależności od potrzeb.\n",
    "\n",
    "Zostały tutaj pominięte pewne standardowe biblioteki jak np. os czy matplotlib."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konfiguracja własnego komputera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeżeli korzystasz z własnego komputera, to musisz zainstalować trochę więcej bibliotek (Google Colab ma je już zainstalowane). Najlepiej używać Pythona 3.9, z którym laboratorium było testowane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anaconda\n",
    "\n",
    "Jeżeli korzystasz z Anacondy (możesz uruchomić w terminalu):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Retrieving notices: ...working... done\n"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge --yes pandas scikit-learn matplotlib missingno imbalanced-learn lightgbm shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### venv\n",
    "\n",
    "Jeżeli używasz zwykłego venv'a (**zdecydowanie niezalecane, szczególnie na Windowsie**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:   \n",
      "  pip install [options] <requirement specifier> [package-index-options] ...\n",
      "  pip install [options] -r <requirements file> [package-index-options] ...\n",
      "  pip install [options] [-e] <vcs project url> ...\n",
      "  pip install [options] [-e] <local project path> ...\n",
      "  pip install [options] <archive url/path> ...\n",
      "\n",
      "no such option: --yes\n"
     ]
    }
   ],
   "source": [
    "!pip install --yes pandas scikit-learn matplotlib missingno imbalanced-learn lightgbm shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W przypadku własnego komputera, jeżeli instalowałeś z terminala, pamiętaj, aby zarejestrować aktualne środowisko wirtualne jako kernel (środowisko uruchomieniowe) dla Jupyter Notebooka. Wybierz go jako używany kernel w menu na górze notebooka (nazwa jak w komendzie poniżej)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!ipython kernel install --user --name \"PSI\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Przygotowanie danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ładowanie danych tabelarycznych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeżeli pracujesz na Google Colab, zacznij od przeniesienia dwóch plików CSV, które zostały dołączone do laboratorium (`titanic.csv` oraz `titanic_test.csv`), do folderu `/content`. Nie musisz ich umieszczać w `/content/sample_data` - ważne, aby znalazły się w `/content`. Jeżeli pracujesz lokalnie, to wystarczy, że pliki te będą obok tego notebooka.\n",
    "\n",
    "Pliki te to dwa zbiory, jeden jest treningowy (czyli z etykietą klasy), a drugi tych etykiet nie posiada. Celem jest oszacowanie na podstawie dostępnych danych tabelarycznych, czy dany pasażer Titanica przeżył katastrofę (etykieta ma wtedy wartość 1), czy miał mniej szczęścia. Dokładny zestaw cech, którymi będziemy dysponować, omówimy sobie w dalszej części laboratorium.\n",
    "\n",
    "Wczytajmy dane `titanic.csv` do zmiennej `train_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(\"titanic.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zobaczmy jakie dane znajdują się w naszej tabeli. Wykorzystajmy do tego metodę `info()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Szczegółowy opis znaczenia kolumn znajdziesz na [pod linkiem](https://www.kaggle.com/competitions/titanic/data?select=train.csv). Zapoznaj się z akapitem **Data Dictionary**. \n",
    "\n",
    "## Wstępna analiza danych\n",
    "\n",
    "W przytłaczającej większości przypadków, zanim zaczniesz robić jakąkolwiek predykcję czy analizę danych, dobrze jest zapoznać się z nimi, z ich kodowaniem i znaczeniem. Kolejnym istotnym aspektem jest typ danych. Otóż nie każdy klasyfikator nadaje się do każdego typu.\n",
    "\n",
    "Wyświetlmy teraz kilka przykładowych rekordów z samej góry korzystając z metody `head()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeżeli potrzebujesz szybko stwierdzić, ile dane zawierają rekordów i kolumn, pomocna okazuje się opcja `shape`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dane kategoryczne\n",
    "\n",
    "Już możemy wysnuć pierwsze wnioski i zauważyć pierwszy problem. Istnieją dwa rodzaje danych: kategoryczne (z ang. *categorical data*) oraz numeryczne (z ang. *numerical data*). Ten podział jest bardzo istotny. Dane numeryczne to żadna niespodzianka, po prostu mają swoją wartość, jak np. **Fare**, czyli opłata za rejs. Dane kategoryczne to takie, którym w większości przypadków nie można przyporządkować wartości liczbowej (wyjątkiem są dane kategoryczne uporządkowane).\n",
    "\n",
    "Wyobraź sobie, że klasyfikujesz kolory i masz wartości RGB. Nie możesz ich zakodować jako np.: R = 0, G = 1 i B = 2. Stwierdzasz tym samym, że w jakimś sensie R < G, R < B i G < B. Nie ma powodu tak sądzić. Istnieje jednak pewien wyjątek. Spójrz na kolumnę **Sex**. Z opisu danych wiesz, że przyjmuje ona dokładnie dwie wartości kategoryczne: *Male* oraz *Female*. W takiej sytuacji wolno Ci zakodować te wartości numerycznie jako 0 i 1. Stwierdzasz tym samym, że ktoś jest **male** albo nie jest. Bez straty w ogólnej definicji problemu możesz zakodować odwrotnie i stwierdzić, że ktoś jest **female** albo nie jest.\n",
    "\n",
    "Wykonaj poniższy kod. Zauważ, że takie zakodowanie cechy miało wpływ na zużycie pamięci (`memory usage`). Jak myślisz, dlaczego?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    int8   \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), int8(1), object(4)\n",
      "memory usage: 77.6+ KB\n"
     ]
    }
   ],
   "source": [
    "from pandas import Categorical\n",
    "\n",
    "train_data[\"Sex\"] = Categorical(train_data[\"Sex\"]).codes\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posiadamy jeszcze jedną kolumnę, która może być dla nas istotna, a zawiera nie dwie, tylko trzy wartości kategoryczne. Jest to kolumna **Embarked**, oznaczająca port, w którym dany pasażer wsiadł. Jak już ustaliliśmy, nie można jej zakodować jako np. 0, 1, 2. Można natomiast usunąć kolumnę **Embarked** i stworzyć trzy nowe, zawierające tylko wartości 0 oraz 1, gdzie 1 oznacza, że pasażer wsiadł w danym porcie. Taką technikę nazywamy z ang. *one-hot encoding*.\n",
    "\n",
    "Zastanów się, co nam daje ta technika, z punktu widzenia wykonywania obliczeń na danych?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name  Sex   Age  SibSp  Parch  \\\n",
       "0                            Braund, Mr. Owen Harris    1  22.0      1      0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0  38.0      1      0   \n",
       "2                             Heikkinen, Miss. Laina    0  26.0      0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    0  35.0      1      0   \n",
       "4                           Allen, Mr. William Henry    1  35.0      0      0   \n",
       "\n",
       "             Ticket     Fare Cabin  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0         A/5 21171   7.2500   NaN           0           0           1  \n",
       "1          PC 17599  71.2833   C85           1           0           0  \n",
       "2  STON/O2. 3101282   7.9250   NaN           0           0           1  \n",
       "3            113803  53.1000  C123           0           0           1  \n",
       "4            373450   8.0500   NaN           0           0           1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import get_dummies\n",
    "\n",
    "train_data = get_dummies(data=train_data, columns=[\"Embarked\"])\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wartości brakujące"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Niestety, ale nasze dane trenujące nie są kompletne. Możesz się o tym przekonać, wykonując poniższy kod:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked_C       0\n",
       "Embarked_Q       0\n",
       "Embarked_S       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Możesz zauważyć, że w naszych danych 177 rekordów (z 891) posiada brakującą informację na temat wieku. Z kolei w 687 rekordach brakuje informacji o numerze kabiny. Biblioteką, która pozwala na zwizualizowanie tych braków, jest *missingno*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 1 (0.5p.)**\n",
    "\n",
    "Stwórz wykres słupkowy brakujących danych zawartych w `train_data` wykorzystując *missingno*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x720 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from missingno import bar\n",
    "bar(train_data, color=\"tomato\", fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skupmy się na kolumnie **Cabin**. Nie będzie nam potrzebna w dalszej predykcji. Po pierwsze są to wartości kategoryczne i jako takie niewiele wnoszą (i tak dysponujemy takimi danymi jak klasa czy opłata). Możemy więc usunąć całą kolumnę."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docelowo będziemy chcieli zastosować strategię numer 4, gdyż dysponujemy odpowiednią liczbą przykładów uczących. Zajmiemy się tym w następnej części laboratorium. \n",
    "\n",
    "## Korelacja atrybutów\n",
    "\n",
    "Analizując pozostałe kolumny, można dojść do wniosku, że imię nie powinno mieć znaczenia w predykcji. Numer biletu to dane kategoryczne, których nie zakodujemy numerycznie. Najzwyczajniej nie miałoby sensu generowanie 891 nowych kolumn. W ramach laboratorium dotyczącego przetwarzania języka dowiemy się, jak można tego rodzaju dane wykorzystać, ale w tym laboratorium po prostu je pominiemy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop(columns=[\"Cabin\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z wiekiem (kolumna **Age**) problem jest większy. Danych brakuje w wielu rekordach, ale nie na tyle wielu, aby tę kolumnę usunąć. Co więcej, może ona być istotna w dalszej predykcji. Musimy się więc zastanowić nad strategią rozwiązania tego problemu. \n",
    "\n",
    "Z brakującymi danymi możemy sobie radzić w sposób następujący:\n",
    "1. Usunąć kolumnę, która zawiera brakujące wartości,\n",
    "1. Usunąć wiersze, w których brakuje wartości,\n",
    "1. Zastąpić brakujące wartości innymi, np. średnią z kolumny, medianą albo wielkością stałą,\n",
    "1. Przewidzieć brakujące wartości wykorzystując odpowiedni model uczenia maszynowego.\n",
    "\n",
    "Ustaliliśmy przed chwilą, że w tym przypadku nie interesują nas rozwiązania 1 oraz 2. Spróbujmy rozwiązania numer 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 2 (0.5p.)**\n",
    "\n",
    "Zastąp brakujące dane w kolumnie **Age** średnią z tej kolumny. \n",
    "\n",
    "**UWAGA** - jeśli wykonujesz operację tego rodzaju, to warto zostawić oryginalne dane, np. żeby poeksperymentować z różnymi metodami uzupełniania danych. Tak też należy zrobić w tym przypadku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = train_data.copy(deep=True)\n",
    "data2 = data2.fillna(train_data[\"Age\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 3 (0.5p.)**\n",
    "\n",
    "Usuń kolumny **Name** oraz **Ticket** ze zbioru trenującego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Sex          891 non-null    int8   \n",
      " 4   Age          714 non-null    float64\n",
      " 5   SibSp        891 non-null    int64  \n",
      " 6   Parch        891 non-null    int64  \n",
      " 7   Fare         891 non-null    float64\n",
      " 8   Embarked_C   891 non-null    uint8  \n",
      " 9   Embarked_Q   891 non-null    uint8  \n",
      " 10  Embarked_S   891 non-null    uint8  \n",
      "dtypes: float64(2), int64(5), int8(1), uint8(3)\n",
      "memory usage: 52.3 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "train_data = train_data.drop(inplace=False, columns=\"Name\")\n",
    "train_data = train_data.drop(inplace=False, columns=\"Ticket\")\n",
    "print(train_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ale jest jeszcze coś. Pomoże nam w tym macierz korelacji. Wykonaj poniższy kod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.005007</td>\n",
       "      <td>-0.035144</td>\n",
       "      <td>0.042939</td>\n",
       "      <td>0.036847</td>\n",
       "      <td>-0.057527</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>-0.001205</td>\n",
       "      <td>-0.033606</td>\n",
       "      <td>0.022148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>-0.005007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>-0.543351</td>\n",
       "      <td>-0.077221</td>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.257307</td>\n",
       "      <td>0.168240</td>\n",
       "      <td>0.003650</td>\n",
       "      <td>-0.155660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.035144</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.131900</td>\n",
       "      <td>-0.369226</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.549500</td>\n",
       "      <td>-0.243292</td>\n",
       "      <td>0.221009</td>\n",
       "      <td>0.081720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0.042939</td>\n",
       "      <td>-0.543351</td>\n",
       "      <td>0.131900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.093254</td>\n",
       "      <td>-0.114631</td>\n",
       "      <td>-0.245489</td>\n",
       "      <td>-0.182333</td>\n",
       "      <td>-0.082853</td>\n",
       "      <td>-0.074115</td>\n",
       "      <td>0.125722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.036847</td>\n",
       "      <td>-0.077221</td>\n",
       "      <td>-0.369226</td>\n",
       "      <td>0.093254</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.308247</td>\n",
       "      <td>-0.189119</td>\n",
       "      <td>0.096067</td>\n",
       "      <td>0.036261</td>\n",
       "      <td>-0.022405</td>\n",
       "      <td>-0.032523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>-0.057527</td>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>-0.114631</td>\n",
       "      <td>-0.308247</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>0.159651</td>\n",
       "      <td>-0.059528</td>\n",
       "      <td>-0.026354</td>\n",
       "      <td>0.070941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>-0.001652</td>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.245489</td>\n",
       "      <td>-0.189119</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.216225</td>\n",
       "      <td>-0.011069</td>\n",
       "      <td>-0.081228</td>\n",
       "      <td>0.063036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.012658</td>\n",
       "      <td>0.257307</td>\n",
       "      <td>-0.549500</td>\n",
       "      <td>-0.182333</td>\n",
       "      <td>0.096067</td>\n",
       "      <td>0.159651</td>\n",
       "      <td>0.216225</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.269335</td>\n",
       "      <td>-0.117216</td>\n",
       "      <td>-0.166603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_C</th>\n",
       "      <td>-0.001205</td>\n",
       "      <td>0.168240</td>\n",
       "      <td>-0.243292</td>\n",
       "      <td>-0.082853</td>\n",
       "      <td>0.036261</td>\n",
       "      <td>-0.059528</td>\n",
       "      <td>-0.011069</td>\n",
       "      <td>0.269335</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.148258</td>\n",
       "      <td>-0.778359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_Q</th>\n",
       "      <td>-0.033606</td>\n",
       "      <td>0.003650</td>\n",
       "      <td>0.221009</td>\n",
       "      <td>-0.074115</td>\n",
       "      <td>-0.022405</td>\n",
       "      <td>-0.026354</td>\n",
       "      <td>-0.081228</td>\n",
       "      <td>-0.117216</td>\n",
       "      <td>-0.148258</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.496624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_S</th>\n",
       "      <td>0.022148</td>\n",
       "      <td>-0.155660</td>\n",
       "      <td>0.081720</td>\n",
       "      <td>0.125722</td>\n",
       "      <td>-0.032523</td>\n",
       "      <td>0.070941</td>\n",
       "      <td>0.063036</td>\n",
       "      <td>-0.166603</td>\n",
       "      <td>-0.778359</td>\n",
       "      <td>-0.496624</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             PassengerId  Survived    Pclass       Sex       Age     SibSp  \\\n",
       "PassengerId     1.000000 -0.005007 -0.035144  0.042939  0.036847 -0.057527   \n",
       "Survived       -0.005007  1.000000 -0.338481 -0.543351 -0.077221 -0.035322   \n",
       "Pclass         -0.035144 -0.338481  1.000000  0.131900 -0.369226  0.083081   \n",
       "Sex             0.042939 -0.543351  0.131900  1.000000  0.093254 -0.114631   \n",
       "Age             0.036847 -0.077221 -0.369226  0.093254  1.000000 -0.308247   \n",
       "SibSp          -0.057527 -0.035322  0.083081 -0.114631 -0.308247  1.000000   \n",
       "Parch          -0.001652  0.081629  0.018443 -0.245489 -0.189119  0.414838   \n",
       "Fare            0.012658  0.257307 -0.549500 -0.182333  0.096067  0.159651   \n",
       "Embarked_C     -0.001205  0.168240 -0.243292 -0.082853  0.036261 -0.059528   \n",
       "Embarked_Q     -0.033606  0.003650  0.221009 -0.074115 -0.022405 -0.026354   \n",
       "Embarked_S      0.022148 -0.155660  0.081720  0.125722 -0.032523  0.070941   \n",
       "\n",
       "                Parch      Fare  Embarked_C  Embarked_Q  Embarked_S  \n",
       "PassengerId -0.001652  0.012658   -0.001205   -0.033606    0.022148  \n",
       "Survived     0.081629  0.257307    0.168240    0.003650   -0.155660  \n",
       "Pclass       0.018443 -0.549500   -0.243292    0.221009    0.081720  \n",
       "Sex         -0.245489 -0.182333   -0.082853   -0.074115    0.125722  \n",
       "Age         -0.189119  0.096067    0.036261   -0.022405   -0.032523  \n",
       "SibSp        0.414838  0.159651   -0.059528   -0.026354    0.070941  \n",
       "Parch        1.000000  0.216225   -0.011069   -0.081228    0.063036  \n",
       "Fare         0.216225  1.000000    0.269335   -0.117216   -0.166603  \n",
       "Embarked_C  -0.011069  0.269335    1.000000   -0.148258   -0.778359  \n",
       "Embarked_Q  -0.081228 -0.117216   -0.148258    1.000000   -0.496624  \n",
       "Embarked_S   0.063036 -0.166603   -0.778359   -0.496624    1.000000  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from seaborn import heatmap\n",
    "\n",
    "heatmap(train_data.corr())\n",
    "train_data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To, co widzisz to macierz korelacji (pod spodem reprezentacja graficzna). Współczynniki w macierzy korelacji to tzw. współczynniki korelacji [Pearsona](https://www.statisticshowto.com/probability-and-statistics/correlation-coefficient-formula/). Współczynnik ten oznaczamy jako *r* i przyjmuje on wartości z przedziału [-1, 1], gdzie -1 oznacza silną korelację ujemną (wysokim wartościom jednej cechy odpowiadają niskie drugiej lub odwrotnie), a 1 oznacza silną korelację dodatnią (wysokim wartościom jednej cechy odpowiadają wysokie wartości drugiej i odwrotnie). Taka macierz pozwala nam zweryfikować, czy w naszym zbiorze danych nie ma redundancji. Bardzo często korzystamy wówczas z wartości bezwzględnej *r*, gdyż interesuje nas fakt czy korelacja w ogóle jest, czy jej nie ma.\n",
    "\n",
    "W tworzeniu modelu predykcji, najbardziej pożądane cechy posiadają następujące własności:\n",
    "- mają niski współczynnik korelacji z innymi cechami (chcemy, aby kolumny niosły jak najwięcej różnych informacji)\n",
    "- wysoki współczynnik korelacji z klasą, którą chcemy przewidywać (chcemy, aby kolumny z cechami mówiły jak najwięcej o klasie, którą będziemy przewidywać)\n",
    "\n",
    "Analizując powyższe macierze, zauważyć można, że kolumna **PassengerId** nie jest silnie skorelowana w zasadzie z niczym, a w szczególności z **Age** oraz **Survived** (która to kolumna będzie nas później interesować)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop(inplace=False, columns=\"PassengerId\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mamy jeszcze problem. Przed zakodowaniem kolumny **Embarked** nie sprawdziliśmy, czy przypadkiem nie brakowało tam jakichś wartości. Jeżeli brakowało, to będziemy mieli wiersze, gdzie w każdej nowej kolumnie **Embarked** (C, Q, S) będzie zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 4 (0.5p.)**\n",
    "\n",
    "Sprawdź, czy ma miejsce sytuacja, w której w danym wierszu **Embarked_C == Embarked_Q == Embarked_S == 0**. Jeżeli liczba takich rekordów jest mała - usuń je ze zbioru `train_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data[(train_data['Embarked_C'] == 0) & (train_data['Embarked_Q'] == 0) & (train_data['Embarked_S'] == 0)]))\n",
    "\n",
    "train_data = train_data[(train_data['Embarked_C'] != 0) | (train_data['Embarked_Q'] != 0) | (train_data['Embarked_S'] != 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skalowanie wartości\n",
    "\n",
    "Ostatnim elementem preprocessingu danych jest ich skalowanie. Zastanów się, co by się stało, gdyby wartości w jednej kolumnie wynosiły np. `[10000, 100000]`, a w drugiej `[1, 10]`. Często takie zjawisko może powodować zaburzenia w trenowaniu modelu oraz jakości predykcji. Wszakże każdy algorytm w końcu sprowadza się do dodawania, mnożenia, dzielenia itp. Więcej informacji na temat tego, dlaczego skalowanie jest aż tak istotne, możesz znaleźć [tu](https://analyticsindiamag.com/why-data-scaling-is-important-in-machine-learning-how-to-effectively-do-it/).\n",
    "\n",
    "Wykonajmy poniższy kod. Skaluje on wartości numeryczne z kolumn do przedziału `[0, 1]` z wykorzystaniem `MinMaxScaler`. Skalowanie odbywa się osobno dla każdej cechy.\n",
    "\n",
    "**Uwaga**: zawsze zapisuj nazwy kolumn, gdyż funkcja ta zwraca tablicę numpy, pozbawiona jest informacji o nazwach atrybutów. Zauważ też, że operujemy tylko na danych treningowych (w kontekście kolumny **Survived**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.271174</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472229</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.321438</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex       Age  SibSp  Parch      Fare  Embarked_C  \\\n",
       "0       0.0     1.0  1.0  0.271174  0.125    0.0  0.014151         0.0   \n",
       "1       1.0     0.0  0.0  0.472229  0.125    0.0  0.139136         1.0   \n",
       "2       1.0     1.0  0.0  0.321438  0.000    0.0  0.015469         0.0   \n",
       "3       1.0     0.0  0.0  0.434531  0.125    0.0  0.103644         0.0   \n",
       "4       0.0     1.0  1.0  0.434531  0.000    0.0  0.015713         0.0   \n",
       "\n",
       "   Embarked_Q  Embarked_S  \n",
       "0         0.0         1.0  \n",
       "1         0.0         0.0  \n",
       "2         0.0         1.0  \n",
       "3         0.0         1.0  \n",
       "4         0.0         1.0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pandas import DataFrame\n",
    "\n",
    "data_columns = train_data.columns\n",
    "scaler = MinMaxScaler()\n",
    "train_data = DataFrame(scaler.fit_transform(train_data))\n",
    "train_data.columns = data_columns\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ten podrozdział pokrył kluczowe aspekty przygotowania danych. Ale jest jeszcze jedna rzecz, którą trzeba wiedzieć. Czasami optymalnym rozwiązaniem jest generowanie zupełnie nowych atrybutów (w oparciu o te istniejące) i używanie tych nowych atrybutów w procesie trenowania modelu. Takim algorytmem jest np. [YAGGA](https://docs.rapidminer.com/8.0/studio/operators/modeling/optimization/feature_generation/optimize_by_generation_yagga2.html) (wykorzystywana w innym popularnym środowisku do uczenia maszynowego, jakim jest RapidMinerStudio). Przy czym dla powyższego przykładu wykorzystanie tego algorytmu byłoby nieuzasadnione. Poza tym biblioteka sklearn nie posiada tego algorytmu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresja liniowa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regresja liniowa jest jednym z najprostszych modeli predykcyjnych. Nadaje się ona do predykcji danych numerycznych, a więc w naszym przypadku np. do predykcji danych w kolumnie **Age**. Prosta regresja liniowa, dla 1 zmiennej, wyraża się wzorem:\n",
    "\n",
    "$$\n",
    "y = ax + b,\n",
    "$$\n",
    "\n",
    "gdzie *y* to zmienna zależna, *x* to zmienna niezależna, a współczynniki *a* i *b* liczone są wg wzorów opisanych [tu](https://www.vedantu.com/formula/linear-regression-formula), bez wątpienia znanych Ci z algebry liniowej.\n",
    "\n",
    "Pewnym rozwinięciem regresji liniowej jest Wielokrotna Regresja Liniowa (*Multiple Linear Regression*, *MLR*), która pozwala na wykorzystanie więcej niż jednej cechy do predykcji wartości. Stanowi ona de facto kombinację liniową pojedynczych cech. Więcej o tym mechanizmie możesz przeczytać [tu](https://rankia.pl/analizy-gieldowe/co-to-jest-wielokrotna-regresja-liniowa-mlr/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przygotujmy się do naszej pierwszej predykcji. Z całości zbioru `train_data` wyodrębnimy te przykłady, w których nie brakuje danych z kolumny **Age**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_linear = train_data.dropna(inplace=False, subset=[\"Age\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podział na zbiór treningowy i testowy\n",
    "\n",
    "Nasz zbiór `train_data_linear` podzielmy na dwa podzbiory: trenujący (75%) i testowy (25%). Trenujący pozwoli nam utworzyć model regresji liniowej, natomiast testowy - oszacować jej jakość. W tym momencie do predykcji wieku użyjemy tylko cechy **SibSp** (dla przykładu), będzie to więc klasyczna regresja liniowa. Pamiętaj, że wyniki uzyskiwane przez model na danych treningowych nie są wiarygodne. Konieczne jest sprawdzenie, jak model radzi sobie na danych testowych.\n",
    "\n",
    "**Uwaga**: W eksperymentach ustalamy na sztywno wartość parametru `random_state`. [Doczytaj](https://scikit-learn.org/stable/glossary.html#term-random_state), dlaczego wykorzystywany jest ten parametr i co się dzieje, gdy jest on równy zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = train_data_linear[\"SibSp\"]\n",
    "y = train_data_linear[\"Age\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.25, random_state=0, shuffle=True\n",
    ")\n",
    "x_train = x_train.values.reshape(-1, 1)\n",
    "x_test = x_test.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trening modelu regresji\n",
    "\n",
    "Na poniższym przykładzie możesz zobaczyć, jak trenujemy model oraz jak wygląda jego reprezentacja graficzna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x219a8418790>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(x_train, y_train)\n",
    "predict = model.predict(x_test)\n",
    "\n",
    "plt.scatter(x_test, y_test, color=\"black\")\n",
    "plt.xlabel(\"SibSp\")\n",
    "plt.ylabel(\"Age\")\n",
    "plt.plot(x_test, predict, color=\"red\", linewidth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ocena jakości modelu\n",
    "\n",
    "Pytanie: skąd wiemy, czy nasz model działa dobrze, czy też źle? W regresji liniowej mamy do tego dwa podstawowe wskaźniki: Współczynnik determinacji (`r2_score`), który pokazuje, jak silna jest korelacja pomiędzy modelem, a próbą (im bliżej 1, tym lepiej), oraz błąd średniokwadratowy (**MSE** - *mean square error*), który pokazuje błąd średniokwadratowy naszego modelu (im bliżej 0, tym lepiej). Wykonaj poniższy kod, aby obliczyć oba te współczynniki dla wytrenowanego modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06837157569534669\n",
      "0.03424820189222956\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2 = r2_score(y_test, predict)\n",
    "MSE = mean_squared_error(y_test, predict)\n",
    "print(r2)\n",
    "print(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nasza wartość MSE jest przyzwoita, stosunkowo blisko zera. Zauważ natomiast, że współczynnik determinacji jest także bliski zeru. Czy to źle? Cóż, w naszym przypadku istotniejszy jest MSE. To, że nasz model przewiduje raz wiek zbyt duży, a raz zbyt mały, nie jest dla nas aż tak istotne, gdyż różnica od wieku prawdziwego jest niewielka. Pamiętaj jednak, że w przypadku wartości MSE istotna jest też skala (przedział) danych, które przewidujemy. Powyższa wartość MSE nie byłaby aż tak korzystna, gdyby przeskalowana wartość **AGE** wahała się np. w przedziale $[0, 0.03]$. Tak jednak nie jest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0041467705453631576\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(min(y_test))\n",
    "print(max(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[\"*You can have a very good MSE for a model which has a very poor R-squared. It just means that the your model has a low error when predicting values but there is very little correlation between the variables. These are statistical measures anyway.*\"](https://www.researchgate.net/post/Why_my_regression_model_shows_good_MSE_but_bad_R-squared_value)\n",
    "\n",
    "**Uwaga:** r2 używamy zazwyczaj na zbiorze treningowym. Jeżeli jesteś ciekawy dlaczego, [tu](https://stats.stackexchange.com/questions/348330/should-r2-be-calculated-on-training-data-or-test-data) znajdziesz interesującą dyskusję na ten temat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Walidacja skrośna\n",
    "\n",
    "Taki jednorazowy podział na zbiór trenujący i testowy (zwany zresztą z ang. *Split Validation* albo *Holdout*) może jednak dawać przekłamane wyniki, w szczególności, jeśli zbiór danych jest mały. Dlatego do weryfikacji jakości predykcji możemy również użyć walidacji skrośnej (z ang. *Cross Validation*). Walidacja skrośna polega na tym, że całość zbioru trenującego jest dzielona na K równych podzbiorów (tzw. *foldów*). Każdy podzbiór raz jest zbiorem testowym, a wówczas reszta staje się zbiorem trenującym. Koniec końców otrzymujemy więc K wyników, które możemy uśrednić i obliczyć z nich odchylenie standardowe. Spójrz na poniższy przykład."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.05866752037410637  std:  0.08499712828400943\n",
      "mean:  -0.030239495851148993  std:  0.004209592980124556\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from statistics import mean, stdev\n",
    "\n",
    "x = x.values.reshape(-1, 1)\n",
    "\n",
    "scores_r2 = cross_val_score(model, x, y, scoring=\"r2\", cv=10)\n",
    "scores_mse = cross_val_score(model, x, y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "print(\"mean: \", mean(scores_r2), \" std: \", stdev(scores_r2))\n",
    "print(\"mean: \", mean(scores_mse), \" std: \", stdev(scores_mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takie wyniki są znacznie bardziej wiarygodne. Typową liczbą podzbiorów jest 5-10 (zwykle im większy zbiór, tym mniej podzbiorów - aby zaoszczędzić czas).\n",
    "\n",
    "## Wykorzystanie wielu cech\n",
    "\n",
    "Dlaczego mamy korzystać tylko z jednej cechy w naszej predykcji? Spróbujmy nasz model rozbudować. Może zastosowanie wszystkich cech będzie lepszym rozwiązaniem? A może jakiegoś ich podzbioru?\n",
    "\n",
    "Przeanalizuj poniższy kod. Zauważ, że z tymczasowych danych trenujących *x* usunięta zostaje kolumna **Survived**. Jest to konieczne, ponieważ, docelowo (gdy już uzupełnimy **Age**) będzie to kolumna, którą będziemy chcieli przewidywać. Nie chcemy przewidywać danych w **Survived** z użyciem danych **Age** przewidzianych z wykorzystaniem **Survived**, bo to może zaburzyć wyniki predykcji w dalszym etapie naszego laboratorium. \n",
    "\n",
    "## Wyszukiwanie hiperparametrów na siatce\n",
    "\n",
    "Zauważ także, że używamy ekstraktora cech `RFE` (feature selection). Przekazując do niego model, możemy zdecydować ile cech ma on wyekstrahować. Ale my nie chcemy tego robić dla każdej kombinacji cech oddzielnie, wprowadzając ich liczbę \"z palca\". Wolelibyśmy, żeby optymalna liczba tych cech została określona eksperymentalnie.\n",
    "\n",
    "Tutaj z pomocą przychodzi [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). Jest to klasa, której najważniejsze parametry to: model, lista parametrów do optymalizowania modelu (właściwa dla danego modelu, RFE posiada jeden istotny parametr (zwany n_features_to_select) oraz krotność podzbiorów. \n",
    "\n",
    "**Uwaga**: doczytaj w dokumentacji co to jest `neg_mean_squared_error`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_features_to_select': 7}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "folds = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "hyper_params = [{\"n_features_to_select\": list(range(1, train_data.shape[1]))}]\n",
    "\n",
    "X = train_data_linear.drop(inplace=False, columns=[\"Age\"]).drop(columns=\"Survived\")\n",
    "model.fit(X, y)\n",
    "model_rfe = RFE(model)\n",
    "\n",
    "model_cv = GridSearchCV(\n",
    "    estimator=model_rfe,\n",
    "    param_grid=hyper_params,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    cv=folds,\n",
    "    verbose=1,\n",
    "    return_train_score=True,\n",
    ")\n",
    "\n",
    "model_cv.fit(X, y)\n",
    "model_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wiemy już, że nie wszystkie cechy są tak samo istotne. Razem jest ich 9 (usunęliśmy kolumnę **Survived**), ale dzięki RFE wiemy, że optymalne rozwiązanie otrzymamy z wykorzystaniem ośmiu z nich. Czas użyć trochę nowej wiedzy w praktyce."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trening ulepszonego modelu regresji\n",
    "\n",
    "**Zadanie 5 (2p.)**\n",
    "\n",
    "Celem jest zastąpienie wartości NaN z kolumny **Age** w zbiorze `train_data` przewidzianymi wartościami.\n",
    "\n",
    "Wykonaj poniższe czynności:\n",
    "1. Przygotuj tymczasową zmienną `y_train` zawierającą dane z kolumny **Age** ze zbioru `train_data_linear`.\n",
    "1. Przygotuj zmienną `x_train` zawierającą wszystkie kolumny z `train_data_linear` za wyjątkiem kolumn **Survived** oraz **Age**.\n",
    "1. Przygotuj zmienną `x_test` na podstawie pierwotnego zbioru trenującego: `train_data`. `x_test` powinno zawierać wszystkie te rekordy, gdzie **Age** jest NaN. Po wyselekcjonowaniu tych rekordów, usuń z `x_test` kolumny **Age** oraz **Survived**.\n",
    "1. Wytrenuj model regresji liniowej na podstawie danych (`x_train, y_train`), z wykorzystaniem `RFE` z ustaloną liczbą cech równą 8 (wybrane na podstawie poprzedniej analizy).\n",
    "1. Wykorzystaj model do predykcji wartości **Age** dla zbioru `x_test`, wyniki zapisz w zmiennej `predict`.\n",
    "1. W oryginalnym zbiorze danych `train_data`, zastąp wartości NaN z kolumny **Age** wartościami ze zmiennej `predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 889 entries, 0 to 888\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Survived    889 non-null    float64\n",
      " 1   Pclass      889 non-null    float64\n",
      " 2   Sex         889 non-null    float64\n",
      " 3   Age         889 non-null    object \n",
      " 4   SibSp       889 non-null    float64\n",
      " 5   Parch       889 non-null    float64\n",
      " 6   Fare        889 non-null    float64\n",
      " 7   Embarked_C  889 non-null    float64\n",
      " 8   Embarked_Q  889 non-null    float64\n",
      " 9   Embarked_S  889 non-null    float64\n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 69.6+ KB\n"
     ]
    }
   ],
   "source": [
    "y_train = train_data_linear[\"Age\"]\n",
    "x_train = train_data_linear.drop(inplace=False, columns=[\"Age\"]).drop(inplace=False, columns=[\"Survived\"])\n",
    "X_test = train_data[train_data[\"Age\"].isna()].drop(inplace=False, columns=[\"Age\"]).drop(inplace=False, columns=[\"Survived\"])\n",
    "\n",
    "model = LinearRegression()\n",
    "model_rfe = RFE(model)\n",
    "\n",
    "predict = model_rfe.fit(x_train, y_train)\n",
    "\n",
    "train_data.loc[train_data[\"Age\"].isna(), \"Age\"] = predict\n",
    "\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tak oto udało nam się poradzić z brakującymi wartościami w kolumnie **Age**. Nasz zbiór `train_data` jest kompletny i może posłużyć jako treningowy do zadania klasyfikacji związanego z kolumną **Survived**.\n",
    "\n",
    "## Wczytanie danych testowych\n",
    "\n",
    "Zanim zajmiemy się jednak klasyfikacją, musimy wczytać dane testowe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 6 (2p.)**\n",
    "\n",
    "Wykonaj poniższe czynności:\n",
    "1. Wczytaj dane testowe `titanic_test.csv`.\n",
    "1. Zapoznaj się z danymi, sprawdź, czy brakuje kolumn/rekordów.\n",
    "1. Opracuj dane testowe tak, aby była możliwa predykcja klasy **Survived**. W szczególności pamiętaj o:\n",
    "* przekonwertowaniu odpowiednich kolumn z kategorycznych na numeryczne,\n",
    "* usunięciu odpowiednich kolumn,\n",
    "* odpowiednim przeskalowaniu danych,\n",
    "* uzupełnieniu brakujących wartości **Age**, wykorzystaj już wytrenowany klasyfikator,\n",
    "* podejmij decyzję, co zrobić z brakującą wartością **Fare**.\n",
    "\n",
    "Gdy wykonasz wszystko powyższe, zwizualizuj dane testowe z użyciem metody `matrix()` z biblioteki missingno. W danych testowych nie powinno być wartości brakujących.\n",
    "\n",
    "Pamiętaj o nazwach kolumn, w zbiorze trenującym i testowym muszą być takie same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'my_train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [56]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmy_train_data\u001b[49m\u001b[38;5;241m.\u001b[39minfo()\n\u001b[0;32m      2\u001b[0m my_train_data_linear \u001b[38;5;241m=\u001b[39m my_train_data\u001b[38;5;241m.\u001b[39mdropna(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      3\u001b[0m y_train \u001b[38;5;241m=\u001b[39m my_train_data_linear[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'my_train_data' is not defined"
     ]
    }
   ],
   "source": [
    "my_train_data.info()\n",
    "my_train_data_linear = my_train_data.dropna(inplace=False, subset=[\"Age\"])\n",
    "y_train = my_train_data_linear['Age']\n",
    "X_train = my_train_data_linear.drop(columns=[\"Age\"])\n",
    "X_test = my_train_data[my_train_data[\"Age\"].isna()].drop(columns=[\"Age\"])\n",
    "\n",
    "model_ = LinearRegression()\n",
    "rfe_model = RFE(model)\n",
    "\n",
    "predict = rfe_model.fit(X_train, y_train)\n",
    "\n",
    "my_train_data.loc[my_train_data[\"Age\"].isna(), \"Age\"] = predict\n",
    "train_data.info()\n",
    "matrix(my_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresja logistyczna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regresja logistyczna jest modelem, który pozwala na przewidywanie wartości zmiennych dychotomicznych (binarnych), w oparciu o jedną lub większą ilość cech. Funkcją bazową regresji logistycznej jest funkcja logistyczna:\n",
    "\n",
    "$$\n",
    "y = \\sigma(x) = \\frac{1}{1 + e^{-(ax + b)}}\n",
    "$$\n",
    "\n",
    "Funkcja ta jest bardzo podobna do regresji liniowej (współczynniki, których uczy się model to $a$ oraz $b$), ale wartości tej funkcji ograniczone są do zbioru $[0,1]$. Dzięki temu można bardzo łatwo zmapować te wartości na zbiór dwuelementowy: 0 i 1, wygodny do klasyfikacji - jeśli wartość funkcji jest > 0.5, to mapowana jest ona na 1, w przeciwnym razie na 0. Bardzo ciekawe podsumowanie teoretycznych podstaw regresji logistycznej znajdziesz [tu](https://philippmuens.com/logistic-regression-from-scratch).\n",
    "\n",
    "Zmienne dychotomiczne to inaczej zmienne, które przyjmują jedynie dwie wartości. Przykładem jest nasza kolumna **Survived** z danych trenujących. Podzielmy więc zbiór trenujący (zawierający etykiety klasy) na podzbiory do trenowania i testowania modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 889 entries, 0 to 888\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Survived    889 non-null    float64\n",
      " 1   Pclass      889 non-null    float64\n",
      " 2   Sex         889 non-null    float64\n",
      " 3   Age         889 non-null    object \n",
      " 4   SibSp       889 non-null    float64\n",
      " 5   Parch       889 non-null    float64\n",
      " 6   Fare        889 non-null    float64\n",
      " 7   Embarked_C  889 non-null    float64\n",
      " 8   Embarked_Q  889 non-null    float64\n",
      " 9   Embarked_S  889 non-null    float64\n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 69.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()\n",
    "\n",
    "X = train_data.drop(inplace=False, columns=[\"Survived\"])\n",
    "y = train_data[\"Survived\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=0, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ocena poprawności klasyfikacji\n",
    "\n",
    "Wytrenujmy nasz pierwszy model i oszacujmy jego dokładność."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'RFE'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [57]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m LogisticRegression()\n\u001b[1;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mscore(X_test, y_test)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1508\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1506\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[1;32m-> 1508\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1510\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1513\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1514\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mliblinear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaga\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1515\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1516\u001b[0m check_classification_targets(y)\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:581\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    579\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 581\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    582\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:964\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    961\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    962\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my cannot be None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 964\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    979\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric)\n\u001b[0;32m    981\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:746\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    744\u001b[0m         array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mastype(dtype, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    745\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 746\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    749\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    750\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2064\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2063\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m-> 2064\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'RFE'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "74% - nieźle, ale może da się ten wynik poprawić. Problem, którym teraz się zajmujemy to problem klasyfikacji. W problemach klasyfikacji mamy dwie główne miary jakości modelu. Jest to dokładność (z ang. *accuracy*) albo tzw. AUC (z ang. *Area Under [ROC] Curve*).\n",
    "Dokładność jest dość intuicyjną miarą, gdyż jest to liczba poprawnie zaklasyfikowanych przykładów (z obu kategorii), podzielona przez liczbę wszystkich przykładów podlegających klasyfikacji:\n",
    "\n",
    "$$\n",
    "Acc = \\frac{TP+TN}{TP+TN+FP+FN},\n",
    "$$\n",
    "\n",
    "gdzie: \n",
    "\n",
    "* $TP$ (true positives) - liczba pozytywnych przypadków (np. osób, które przeżyły katastrofę) zaklasyfikowanych poprawnie,\n",
    "* $TN$ (true negatives) - liczba negatywnych przypadków (np. osób, które nie przeżyły katastrofy) zaklasyfikowanych poprawnie,\n",
    "* $FP$ (false positives) - liczba pozytywnych przypadków, zaklasyfikowanych błędnie,\n",
    "* $FN$ (false negatives) - liczba negatywnych przypadków, zaklasyfikowanych błędnie.\n",
    "\n",
    "Dokładności używamy, gdy klasy rozłożone są w miarę równomiernie, a AUC, gdy jedna klasa jest dominująca. Sprawdźmy, jak jest w naszym przypadku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_0 = y[y == 0].size\n",
    "y_1 = y[y == 1].size\n",
    "print(\"0:\", y_0)\n",
    "print(\"1:\", y_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uznajmy, że zbiór ten jest umiarkowanie zbalansowany. Wybierzmy więc `accuracy` jako `scoring`. `roc_auc` wykorzystamy w następnym laboratorium, gdzie zbiór danych będzie znacznie bardziej niezbalansowany.\n",
    "\n",
    "**Zadanie 7 (1p.)**\n",
    "\n",
    "Ustal optymalną liczbę cech do predykcji klasy **Survived**. Skorzystaj z `RFE`, `GridSearchCV` oraz 10-krotnej walidacji skrośnej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ewa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "90 fits failed out of a total of 90.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "90 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ewa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Ewa\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py\", line 222, in fit\n",
      "    return self._fit(X, y, **fit_params)\n",
      "  File \"C:\\Users\\Ewa\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py\", line 231, in _fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"C:\\Users\\Ewa\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\Ewa\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 964, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"C:\\Users\\Ewa\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 746, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"C:\\Users\\Ewa\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\", line 2064, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "TypeError: float() argument must be a string or a number, not 'RFE'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Ewa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ewa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'RFE'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [58]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m model_rfe \u001b[38;5;241m=\u001b[39m RFE(model)\n\u001b[0;32m      6\u001b[0m model_cv \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[0;32m      7\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mmodel_rfe,\n\u001b[0;32m      8\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mhyper_params,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m     return_train_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     13\u001b[0m )\n\u001b[1;32m---> 15\u001b[0m \u001b[43mmodel_cv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m model_cv\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:926\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    924\u001b[0m refit_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    925\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 926\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    927\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:222\u001b[0m, in \u001b[0;36mRFE.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;124;03m\"\"\"Fit the RFE model and then the underlying estimator on the selected features.\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:231\u001b[0m, in \u001b[0;36mRFE._fit\u001b[1;34m(self, X, y, step_score, **fit_params)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, step_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;66;03m# Parameter step_score controls the calculation of self.scores_\u001b[39;00m\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;66;03m# step_score is not exposed to users\u001b[39;00m\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;66;03m# and is used when implementing RFECV\u001b[39;00m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# self.scores_ will not be calculated when calling _fit through fit\u001b[39;00m\n\u001b[0;32m    230\u001b[0m     tags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()\n\u001b[1;32m--> 231\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow_nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m     error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    240\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_to_select must be either None, a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositive integer representing the absolute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mselect. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_to_select\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    245\u001b[0m     )\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;66;03m# Initialization\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:581\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    579\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 581\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    582\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:964\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    961\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    962\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my cannot be None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 964\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    979\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric)\n\u001b[0;32m    981\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:746\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    744\u001b[0m         array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mastype(dtype, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    745\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 746\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    749\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    750\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2064\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2063\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m-> 2064\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'RFE'"
     ]
    }
   ],
   "source": [
    "hyper_params = [{\"n_features_to_select\": list(range(1, train_data.shape[1]))}]\n",
    "\n",
    "folds = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "model_rfe = RFE(model)\n",
    "\n",
    "model_cv = GridSearchCV(\n",
    "    estimator=model_rfe,\n",
    "    param_grid=hyper_params,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=folds,\n",
    "    verbose=1,\n",
    "    return_train_score=True,\n",
    ")\n",
    "\n",
    "model_cv.fit(X_train, y_train)\n",
    "model_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posiadając liczbę cech, ustalmy jaki zestaw parametrów regresji logistycznej ([zobacz parametry](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)) jest optymalny dla naszego problemu. Jako solvera użyjemy modelu *saga*. Jest on szybki i wspiera regularyzację Elastic Net ([zobacz definicję](https://en.wikipedia.org/wiki/Elastic_net_regularization)).\n",
    "\n",
    "## Przeuczenie\n",
    "\n",
    "W trakcie trenowania modelu może dojść do sytuacji, w której zostanie on przeuczony (z ang. *overfitting*). Gdy to się wydarzy, model może mieć bardzo dokładne wyniki, gdy zastosujemy go na danych, które już widział na etapie trenowania. Takie szacowanie jakości modelu jest oczywiście błędem metodologicznym. Przeuczenie modelu jest bardzo istotnym problemem w sztucznej inteligencji i isnieje szereg metod, służących zapobieganiu tego zjawiska. Jedną z nich jest regularyzacja - do globalnej funkcji błędu dodawane są \"kary\": `l1` oraz `l2`, które stanowią miary wielkości parametrów obliczonych w trakcie treningu. Obie te wartości są tak naprawdę normami (odpowiednio `l1` i `l2`) wektorów wag modelu przeskalowane przez określoną wartość (w sklearn określoną jako `C`). Dodawanie tych kar ma zabiec przeuczeniu. Jak słusznie możesz się spodziewać, zbyt duże kary spowoduję z kolei niedouczenie (ang. *underfitting*). Więcej o konstrukcji i zastosowaniach regularyzacji `l1` i `l2` przeczytać możesz [tu](https://towardsdatascience.com/intuitions-on-l1-and-l2-regularisation-235f2db4c261)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 8 (1p.)**\n",
    " \n",
    " Dowiedz się, jaki zestaw parametrów dla naszego problemu jest optymalny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_params_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [61]\u001b[0m, in \u001b[0;36m<cell line: 19>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m model_rfe \u001b[38;5;241m=\u001b[39m RFE(model)\n\u001b[0;32m     13\u001b[0m model_cv \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[0;32m     14\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mmodel_rfe,\n\u001b[0;32m     15\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mhyper_params,\n\u001b[0;32m     16\u001b[0m     cv \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m7\u001b[39m, \n\u001b[0;32m     17\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel_cv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_params_\u001b[49m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_cv\u001b[38;5;241m.\u001b[39mbest_score_)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_params_'"
     ]
    }
   ],
   "source": [
    "hyper_params = {\n",
    "    \"estimator__solver\": [\"saga\"],\n",
    "    \"estimator__C\": [0.001, .009, 0.01, .09, 1, 5],\n",
    "    \"estimator__penalty\": [\"l1\", \"l2\"],\n",
    "    \"estimator__intercept_scaling\": [0.01, 0.1, 1., 10., 20.],\n",
    "    \"estimator__max_iter\": [1000],\n",
    "    \"n_features_to_select\": [7]\n",
    "    }\n",
    "\n",
    "folds = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "model_rfe = RFE(model)\n",
    "\n",
    "model_cv = GridSearchCV(\n",
    "    estimator=model_rfe,\n",
    "    param_grid=hyper_params,\n",
    "    cv = 7, \n",
    "    n_jobs=-1).fit()\n",
    "\n",
    "model_cv.fit(X_train, y_train)\n",
    "\n",
    "print(model_cv.best_params_)\n",
    "print(model_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 9 (1p.)**\n",
    "\n",
    "Wytrenuj optymalny model (parametry dobierz na podstawie poprzednich zadań) oraz dokonaj predykcji brakujących wartości klasy **Survived** dla zbioru `titanic_test.csv`. Wyniki zwizualizuj na wykresie słupkowym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your_code_here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytania kontrolne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(**1p.**)\n",
    "\n",
    "1. Co zrobić z kolumną, która zawiera wartości od \"A\" do \"D\", a powinna zostać wykorzystana przez model?\n",
    "1. Jakie są sposoby radzenia sobie z danymi brakującymi?\n",
    "1. Jak nazwiesz typ wartości dla kolumny, która zawiera tylko i wyłącznie liczby 13 oraz 17?\n",
    "1. Czy stosowanie jednorazowego podziału zbioru na testowy i trenujący jest zawsze niezalecane? Jaka jest inna metoda?\n",
    "1. Czy każda cecha w modelu jest istotna? Jakie znasz metody wybierania podzbiorów cech?\n",
    "1. Jak oszacować skuteczność modelu, który dokonuje predykcji gatunku zwierzęcia, a jak modelu, który przewiduje kurs akcji giełdowych?\n",
    "1. Jakiej wartości korelacji spodziewać się dla danych typu kraj pochodzenia - język, a jakich dla problemu typu *predator - prey*?\n",
    "1. Jakich modeli użyć dla obu problemów opisanych w punkcie wyżej?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Zamienić na 4 kolumny boolean z informacją, czy była tam ta litera\n",
    "2. Usunięcie wybrakowanych wierszy, zastąpienie brakujących wartości stałą (np średnia, 0)\n",
    "3. Dane kategoryczne\n",
    "4. Można rotować zbiory między sobą, trenowanie na tym samym zbiorze może prowadzić do overfittingu\n",
    "5. Istotne są cechy mało ze sobą skorelowane, o możliwie kompletych danych. \n",
    "Korelację można sprawdzić poprzez wygenerowanie macierzy korelacji i na jej podstawie wybrać cechy o niskiej korelacji bezwzględnej.\n",
    "6. Kursu akcji poprzez zestawienie z prawdziwym kursem, \n",
    "7. Korelacja między językiem i krajem pochodzenia będzie wysoka i dodatnia, a dla predator-prey niższa i ujemna."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie dodatkowe *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **(2p.)**\n",
    "\n",
    "Poniższe zadanie jest dodatkowe, nie musisz go wykonać.\n",
    "\n",
    "W tym laboratorium rozważyliśmy dwa rodzaje regresji: liniową i logistyczną. W bibliotece sklearn istnieje jednak kilka innych typów liniowych modeli ([Linear classifiers](https://scikit-learn.org/stable/modules/classes.html?highlight=sklearn+linear_model#module-sklearn.linear_model)). Sprawdź czy dla problemu wieku (**Age**) i/lub klasy **Survived** dasz radę uzyskać wyższą skuteczność niż dla modeli zaproponowanych w laboratorium. Jeżeli Ci się to uda, oszacuj, czy różnica/różnice są znaczące z punktu widzenia statystycznego.\n",
    "\n",
    "Dodatkowo, jeżeli wyżej wspomniane tematy są dla Ciebie interesujące, zapoznaj się z materiałami dodatkowymi: [train-valid-test split](https://mlu-explain.github.io/train-test-validation/), [ROC & AUC](https://mlu-explain.github.io/roc-auc/), [Regresja logistyczna](https://mlu-explain.github.io/logistic-regression/), [MLU Explain](https://mlu-explain.github.io/linear-regression/) oraz [regularyzacja L1 i L2](https://sebastianraschka.com/faq/docs/regularization-linear.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PSI",
   "language": "python",
   "name": "psi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
